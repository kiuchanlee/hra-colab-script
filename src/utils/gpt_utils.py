import re
import os
import math
from typing import List
from openai import OpenAI
import pandas as pd
from utils.logger import log_info, log_error

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

MEDIA_PRIORITY = ["ì¡°ì„ ì¼ë³´", "ì¤‘ì•™ì¼ë³´", "ë™ì•„ì¼ë³´", "ì„œìš¸ì‹ ë¬¸", "ê²½í–¥ì‹ ë¬¸", "í•œê²¨ë ˆ", "í•œêµ­ê²½ì œ", "ë¨¸ë‹ˆíˆ¬ë°ì´"]

def parse_gpt_group_output(content: str) -> List[List[int]]:
    group_strings = re.findall(r'\[([0-9,\s]+)\]', content)
    groups = []
    for group_str in group_strings:
        try:
            numbers = [int(n.strip()) - 1 for n in group_str.split(',')]
            groups.append(numbers)
        except:
            continue
    return groups

def get_gpt_duplicate_groups(headlines: List[str]) -> List[List[int]]:
    system_prompt = "ë„ˆëŠ” ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ì¤‘ ì¤‘ë³µëœ ë‚´ìš©ì„ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ì–´ì£¼ëŠ” AIì•¼."
    user_prompt = "\n".join([f"{i+1}. {h}" for i, h in enumerate(headlines)])
    user_prompt += "\nì¶œë ¥ í˜•ì‹: [[1, 2], [3], [4, 5]]"

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.2
        )
        content = response.choices[0].message.content
        return parse_gpt_group_output(content)
    except Exception as e:
        log_error(f"âš ï¸ ì¤‘ë³µ ì œê±° GPT í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return [[i] for i in range(len(headlines))]

def choose_by_media_priority(group_df: pd.DataFrame) -> pd.Series:
    for media in MEDIA_PRIORITY:
        match = group_df[group_df["ë§¤ì²´ëª…"] == media]
        if not match.empty:
            return match.iloc[0]
    return group_df.iloc[0]

def deduplicate_news_with_gpt(df: pd.DataFrame, batch_size: int = 20) -> pd.DataFrame:
    if df.empty: return df
    df = df.copy().reset_index(drop=True)
    headline_batches = [df.iloc[i:i+batch_size] for i in range(0, len(df), batch_size)]
    selected_rows = []
    for batch_df in headline_batches:
        headlines = batch_df['í—¤ë“œë¼ì¸'].tolist()
        groups = get_gpt_duplicate_groups(headlines)
        for group in groups:
            try:
                # ì•ˆì „í•œ ì¸ë±ìŠ¤ ì ‘ê·¼
                valid_group = [g for g in group if 0 <= g < len(batch_df)]
                if not valid_group: continue
                group_df = batch_df.iloc[valid_group]
                selected = choose_by_media_priority(group_df)
                selected_rows.append(selected)
            except:
                continue
    return pd.DataFrame(selected_rows).reset_index(drop=True)

def deduplicate_news_with_gpt_twopass(df: pd.DataFrame, batch_size_first: int = 20, batch_size_second: int = 50) -> pd.DataFrame:
    first_pass_df = deduplicate_news_with_gpt(df, batch_size=batch_size_first)
    return deduplicate_news_with_gpt(first_pass_df, batch_size=batch_size_second)

def analyze_articles_batch(df: pd.DataFrame, batch_size=5, max_retries=5) -> pd.DataFrame:
    # ì»¬ëŸ¼ ì´ˆê¸°í™”
    for col in ["ëŒ€ê¸°ì—… ê´€ë ¨", "HR ê´€ë ¨", "ì •ì±…/ë²•ì•ˆ ê´€ë ¨", "ê²½ì œ/ì‚°ì—… ê´€ë ¨", "ë³´í—˜/ê¸ˆìœµ ê´€ë ¨", "ì¤‘ìš”ì—¬ë¶€"]:
        df[col] = "X"
    df["ì¤‘ìš”ë„"] = 0

    log_info(f"ğŸ“Œ [2ë‹¨ê³„] ê¸°ì‚¬ ë¶„ì„ ì‹œì‘ (ì´ {len(df)}ê±´, {batch_size}ê°œì”© ë¬¶ìŒ)")
    total_success = 0
    retry_indices = set()

    def run_batch(batch_df, index_map):
        prompt_lines = []
        for i, idx in enumerate(batch_df.index, 1):
            summary = str(batch_df.at[idx, 'ìš”ì•½'])[:200] # í† í° ì ˆì•½ ë° ì—ëŸ¬ ë°©ì§€
            prompt_lines.append(f"{i}. {summary}")
            index_map[i] = idx

        prompt = "\n".join(prompt_lines)
        system_msg = (
            "ë‹¹ì‹ ì€ ëŒ€ê¸°ì—… ì¸ì‚¬íŒ€ì˜ ì¸ì‚¬ ë‹´ë‹¹ìì…ë‹ˆë‹¤.\n"
            "ê° ê¸°ì‚¬ì— ëŒ€í•´ 1.ëŒ€ê¸°ì—… ê´€ë ¨, 2.HR ê´€ì‹¬, 3.ì •ì±…/ë²•ì•ˆ, 4.ê²½ì œ/ì‚°ì—…, 5.ë³´í—˜/ê¸ˆìœµ ì—¬ë¶€ë¥¼ O/Xë¡œ íŒë‹¨í•˜ì„¸ìš”.\n"
            "í˜•ì‹: 1. ëŒ€ê¸°ì—… ê´€ë ¨: O, HR ê´€ì‹¬: O, ì •ì±…/ë²•ì•ˆ/íŒë¡€ ê´€ë ¨: X, ê²½ì œ/ì‚°ì—… ê´€ë ¨: O, ë³´í—˜/ê¸ˆìœµ ê´€ë ¨: X"
        )

        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "system", "content": system_msg}, {"role": "user", "content": prompt}]
            )
            reply = response.choices[0].message.content.strip()
            lines = reply.split("\n")
            
            success_count = 0
            failed_ids = []

            for line in lines:
                if '. ' not in line: continue
                try:
                    parts = line.split('. ', 1)
                    gpt_num = int(re.search(r'\d+', parts[0]).group())
                    content = parts[1]
                    fields = [f.strip() for f in content.split(',')]
                    
                    original_idx = index_map.get(gpt_num)
                    if original_idx is not None and len(fields) >= 5:
                        vals = [f.split(':')[-1].strip() if ':' in f else 'X' for f in fields[:5]]
                        df.at[original_idx, "ëŒ€ê¸°ì—… ê´€ë ¨"] = vals[0]
                        df.at[original_idx, "HR ê´€ë ¨"] = vals[1]
                        df.at[original_idx, "ì •ì±…/ë²•ì•ˆ ê´€ë ¨"] = vals[2]
                        df.at[original_idx, "ê²½ì œ/ì‚°ì—… ê´€ë ¨"] = vals[3]
                        df.at[original_idx, "ë³´í—˜/ê¸ˆìœµ ê´€ë ¨"] = vals[4]
                        
                        score = vals.count("O")
                        df.at[original_idx, "ì¤‘ìš”ë„"] = score
                        df.at[original_idx, "ì¤‘ìš”ì—¬ë¶€"] = "V" if score >= 3 else ""
                        success_count += 1
                except:
                    continue
            
            # ì‘ë‹µì— í¬í•¨ë˜ì§€ ì•Šì€ IDë“¤ì„ ì‹¤íŒ¨ë¡œ ê°„ì£¼
            processed_gpt_nums = [int(re.search(r'\d+', l.split('. ')[0]).group()) for l in lines if '. ' in l and re.search(r'\d+', l.split('. ')[0])]
            for i in index_map:
                if i not in processed_gpt_nums:
                    failed_ids.append(index_map[i])

            return success_count, failed_ids

        except Exception as e:
            log_error(f"âš ï¸ GPT ë°°ì¹˜ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0, list(index_map.values())

    # 1ì°¨ ë¶„ì„ ë£¨í”„
    total_batches = math.ceil(len(df) / batch_size)
    for batch_num in range(total_batches):
        start = batch_num * batch_size
        batch_df = df.iloc[start : start + batch_size]
        index_map = {}
        success, failed = run_batch(batch_df, index_map)
        total_success += success
        retry_indices.update([f for f in failed if f is not None])
        log_info(f"ğŸ“¦ Batch {batch_num+1}/{total_batches}: ì„±ê³µ {success}")

    # ì¬ì‹œë„ ë£¨í”„ (ì—ëŸ¬ ë°©ì–´ ê°•í™”)
    retry_count = 0
    while retry_indices and retry_count < max_retries:
        retry_count += 1
        log_info(f"ğŸ” ì¬ì‹œë„ {retry_count}ì°¨ (ë‚¨ì€ ê¸°ì‚¬: {len(retry_indices)})")
        
        # ğŸ”¥ KeyError ë°©ì–´: None ì œê±° ë° ì‹¤ì œ df.indexì— ì¡´ì¬í•˜ëŠ” ê²ƒë§Œ ì¶”ì¶œ
        current_retry_list = [idx for idx in retry_indices if idx is not None and idx in df.index]
        retry_indices = set()

        for i in range(0, len(current_retry_list), batch_size):
            batch_ids = current_retry_list[i : i + batch_size]
            # í•œ ë²ˆ ë” ì²´í¬ (ì•ˆì „ì¥ì¹˜)
            batch_ids = [b for b in batch_ids if b in df.index]
            if not batch_ids: continue

            batch_df = df.loc[batch_ids]
            index_map = {}
            success, failed = run_batch(batch_df, index_map)
            total_success += success
            retry_indices.update([f for f in failed if f is not None])

    log_info(f"âœ… ë¶„ì„ ì™„ë£Œ: ì´ {total_success}/{len(df)}ê±´ ì„±ê³µ")
    return df
