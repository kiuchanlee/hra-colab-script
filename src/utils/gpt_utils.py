# src/utils/gpt_utils.py

import re
import os
import math
from typing import List
from openai import OpenAI
import pandas as pd

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

MEDIA_PRIORITY = ["ì¡°ì„ ì¼ë³´", "ì¤‘ì•™ì¼ë³´", "ë™ì•„ì¼ë³´", "ì„œìš¸ì‹ ë¬¸", "ê²½í–¥ì‹ ë¬¸", "í•œê²¨ë ˆ", "í•œêµ­ê²½ì œ", "ë¨¸ë‹ˆíˆ¬ë°ì´"]

def parse_gpt_group_output(content: str) -> List[List[int]]:
    group_strings = re.findall(r'\[([0-9,\s]+)\]', content)
    groups = []
    for group_str in group_strings:
        numbers = [int(n.strip()) - 1 for n in group_str.split(',')]
        groups.append(numbers)
    return groups

def get_gpt_duplicate_groups(headlines: List[str]) -> List[List[int]]:
    system_prompt = "ë„ˆëŠ” ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ì¤‘ ì¤‘ë³µëœ ë‚´ìš©ì„ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ì–´ì£¼ëŠ” AIì•¼."
    user_prompt = "\n".join([f"{i+1}. {h}" for i, h in enumerate(headlines)])
    user_prompt += "\nì¶œë ¥ í˜•ì‹: [[1, 2], [3], [4, 5]]"

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.2
    )
    content = response.choices[0].message.content
    return parse_gpt_group_output(content)

def choose_by_media_priority(group_df: pd.DataFrame) -> pd.Series:
    for media in MEDIA_PRIORITY:
        match = group_df[group_df["ë§¤ì²´ëª…"] == media]
        if not match.empty:
            return match.iloc[0]
    return group_df.iloc[0]

def deduplicate_news_with_gpt(df: pd.DataFrame, batch_size: int = 20) -> pd.DataFrame:
    df = df.copy().reset_index(drop=True)
    headline_batches = [df.iloc[i:i+batch_size] for i in range(0, len(df), batch_size)]
    selected_rows = []
    for batch_df in headline_batches:
        headlines = batch_df['í—¤ë“œë¼ì¸'].tolist()
        groups = get_gpt_duplicate_groups(headlines)
        for group in groups:
            group_df = batch_df.iloc[group]
            selected = choose_by_media_priority(group_df)
            selected_rows.append(selected)
    return pd.DataFrame(selected_rows).reset_index(drop=True)

def deduplicate_news_with_gpt_twopass(df: pd.DataFrame, batch_size_first: int = 20, batch_size_second: int = 50) -> pd.DataFrame:
    first_pass_df = deduplicate_news_with_gpt(df, batch_size=batch_size_first)
    return deduplicate_news_with_gpt(first_pass_df, batch_size=batch_size_second)

def analyze_articles_batch(df: pd.DataFrame, batch_size=5, max_retries=5) -> pd.DataFrame:
    df["ëŒ€ê¸°ì—… ê´€ë ¨"] = ""
    df["HR ê´€ë ¨"] = ""
    df["ì •ì±…/ë²•ì•ˆ ê´€ë ¨"] = ""
    df["ê²½ì œ/ì‚°ì—… ê´€ë ¨"] = ""
    df["ë³´í—˜/ê¸ˆìœµ ê´€ë ¨"] = ""
    df["ì¤‘ìš”ì—¬ë¶€"] = ""
    df["ì¤‘ìš”ë„"] = 0

    print(f"\nğŸ“Œ [2ë‹¨ê³„] ê¸°ì‚¬ ë¶„ì„ ì‹œì‘ (ì´ {len(df)}ê±´, {batch_size}ê°œì”© ë¬¶ìŒ)")
    total_success = 0
    total_failed = 0
    retry_indices = set()

    def run_batch(batch_df, index_map):
        prompt_lines = []
        for i, idx in enumerate(batch_df.index, 1):
            prompt_lines.append(f"{i}. {batch_df.at[idx, 'í—¤ë“œë¼ì¸']}")
            index_map[i] = idx

        prompt = "\n".join(prompt_lines)

        system_msg = (
            "ë‹¹ì‹ ì€ ëŒ€ê¸°ì—… ì¸ì‚¬íŒ€ì˜ ì¸ì‚¬ ë‹´ë‹¹ìì…ë‹ˆë‹¤.\n"
            "ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ ì œëª©ë“¤ì„ ê²€í† í•˜ê³  ê° ì œëª©ì— ëŒ€í•´ ë‹¤ìŒ ë‹¤ì„¯ ê°€ì§€ í•­ëª©ì— ëŒ€í•´ ê°ê° 'O' ë˜ëŠ” 'X'ë¡œ íŒë‹¨í•˜ì„¸ìš”.\n\n"
            "1. ì´ ê¸°ì‚¬ê°€ ì‚¼ì„±ê·¸ë£¹ í˜¹ì€ ëŒ€ê¸°ì—…ê³¼ ê´€ë ¨ì´ ìˆëŠ”ê°€?\n"
            "2. ì´ ê¸°ì‚¬ê°€ HR ë¶€ì„œ(ì±„ìš©, ì¸ì‚¬, ì œë„, ì„ê¸ˆ, êµìœ¡, ë…¸ë¬´ ë“±)ì—ì„œ ê´€ì‹¬ì„ ê°€ì§ˆë§Œí•œ ë‚´ìš©ì¸ê°€?\n"
            "3. ì •ì±…/ë²•ì•ˆ ë“±ì˜ ì œë„ ë³€í™”ì™€ ê´€ë ¨ëœ ë‚´ìš©ì¸ê°€?\n"
            "4. ê²½ì œ/ì‚°ì—…ê³„ì™€ ê´€ë ¨ ë‚´ìš©ì¸ê°€?\n"
            "5. ë³´í—˜/ê¸ˆìœµì—…ê³„ ê´€ë ¨ ë‚´ìš©ì¸ê°€?\n\n"
            "ê° ê¸°ì‚¬ì— ëŒ€í•´ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\n"
            "1. ëŒ€ê¸°ì—… ê´€ë ¨: O, HR ê´€ì‹¬: O, ì •ì±…/ë²•ì•ˆ/íŒë¡€ ê´€ë ¨: X, ê²½ì œ/ì‚°ì—… ê´€ë ¨: O, ë³´í—˜/ê¸ˆìœµ ê´€ë ¨: X\n"
            "...\n\n"
            f"ê¸°ì‚¬ ëª©ë¡:\n{prompt}"
        )

        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "system", "content": system_msg}]
            )
            reply = response.choices[0].message.content.strip()
            lines = reply.split("\n")

            success = 0
            failed_ids = []

            for line in lines:
                if not line.strip():
                    continue

                parts = line.split('. ', 1)
                if len(parts) < 2:
                    continue

                try:
                    gpt_num = int(parts[0])
                except:
                    continue

                content = parts[1]
                fields = [f.strip() for f in content.split(',')]
                if len(fields) < 5:
                    failed_ids.append(index_map[gpt_num])
                    continue

                values = []
                for f in fields:
                    if ':' in f:
                        values.append(f.split(':')[1].strip())
                    else:
                        values.append('X')

                original_idx = index_map.get(gpt_num)
                if original_idx is not None and len(values) == 5:
                    df.at[original_idx, "ëŒ€ê¸°ì—… ê´€ë ¨"] = values[0]
                    df.at[original_idx, "HR ê´€ë ¨"] = values[1]
                    df.at[original_idx, "ì •ì±…/ë²•ì•ˆ ê´€ë ¨"] = values[2]
                    df.at[original_idx, "ê²½ì œ/ì‚°ì—… ê´€ë ¨"] = values[3]
                    df.at[original_idx, "ë³´í—˜/ê¸ˆìœµ ê´€ë ¨"] = values[4]

                    relevance_score = values.count("O")
                    df.at[original_idx, "ì¤‘ìš”ë„"] = relevance_score

                    if relevance_score >= 3:
                        df.at[original_idx, "ì¤‘ìš”ì—¬ë¶€"] = "V"

                    success += 1
                else:
                    failed_ids.append(original_idx)

            return success, failed_ids

        except Exception as e:
            print(f"âš ï¸ GPT ë¶„ì„ ì‹¤íŒ¨ (ì˜ˆì™¸): {e}")
            return 0, list(index_map.values())

    total_batches = math.ceil(len(df) / batch_size)
    for batch_num in range(total_batches):
        start_idx = batch_num * batch_size
        end_idx = min(start_idx + batch_size, len(df))
        batch_df = df.iloc[start_idx:end_idx]
        index_map = {}

        print(f"\nğŸ“¦ Batch {batch_num+1}: í¬ë¡¤ë§ ì¤‘...")
        success, failed = run_batch(batch_df, index_map)
        total_success += success
        total_failed += len(batch_df) - success
        retry_indices.update(failed)

        print(f"âœ… ì„±ê³µ: {success} / âŒ ì‹¤íŒ¨: {len(failed)}")

    retry_count = 0
    while retry_indices and retry_count < max_retries:
        retry_count += 1
        print(f"\nğŸ” ì¬ì‹œë„ {retry_count}ì°¨ ì‹œì‘ (ë‚¨ì€ ì‹¤íŒ¨ ê¸°ì‚¬ ìˆ˜: {len(retry_indices)})")

        retry_list = list(retry_indices)
        retry_indices = set()

        for i in range(0, len(retry_list), batch_size):
            batch_ids = retry_list[i:i+batch_size]
            batch_df = df.loc[batch_ids]
            index_map = {}

            success, failed = run_batch(batch_df, index_map)
            total_success += success
            total_failed -= success
            retry_indices.update(failed)

            print(f"â†©ï¸ ì¬ì‹œë„ ì„±ê³µ: {success} / ì‹¤íŒ¨: {len(failed)}")

    print(f"\nâœ… ë¶„ì„ ì™„ë£Œ: ì´ {total_success}ê±´ ì„±ê³µ / {len(df)}ê±´ ì¤‘")
    if total_failed > 0:
        print(f"â— ìµœì¢… ì‹¤íŒ¨ ê¸°ì‚¬: {total_failed}ê±´ (ì¬ì‹œë„ {max_retries}íšŒ í›„ ì‹¤íŒ¨)")

    return df
