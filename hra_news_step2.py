import os
import pandas as pd
from datetime import datetime
import math
from typing import List
from openai import OpenAI
from google.oauth2.service_account import Credentials
import gspread
import re
from gspread_dataframe import set_with_dataframe

# âœ… ì¸ì¦ ì„¤ì •
SCOPES = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
creds = Credentials.from_service_account_file("creds.json", scopes=SCOPES)
gc = gspread.authorize(creds)

# âœ… OpenAI ì„¤ì •
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")  # GitHub Actionsì—ì„œëŠ” secretsë¡œ ì„¤ì •
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))  

# âœ… CSV ë¶ˆëŸ¬ì˜¤ê¸°
df_total = pd.read_csv("crawled_news.csv")
print(f"ğŸ“„ CSV ë¡œë“œ ì™„ë£Œ: {len(df_total)}ê±´")


#âœ… 9. ì¤‘ë³µê¸°ì‚¬ì œê±°
# âœ… ì–¸ë¡ ì‚¬ ìš°ì„ ìˆœìœ„ ë¦¬ìŠ¤íŠ¸ (ì›í•˜ëŠ” ëŒ€ë¡œ ìˆ˜ì • ê°€ëŠ¥)
MEDIA_PRIORITY = ["ì¡°ì„ ì¼ë³´", "ì¤‘ì•™ì¼ë³´", "ë™ì•„ì¼ë³´", "ì„œìš¸ì‹ ë¬¸", "ê²½í–¥ì‹ ë¬¸", "í•œê²¨ë ˆ", "í•œêµ­ê²½ì œ", "ë¨¸ë‹ˆíˆ¬ë°ì´"]

def parse_gpt_group_output(content: str) -> List[List[int]]:
    """
    GPT ì‘ë‹µì—ì„œ ì¤‘ë³µ ê·¸ë£¹ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ (ì˜ˆ: [[1,2], [3], [4,5]])
    """
    try:
        print("ğŸ§  GPT ì‘ë‹µ ì›ë¬¸:", content.strip())
        group_strings = re.findall(r'\[([0-9,\s]+)\]', content)
        groups = []
        for group_str in group_strings:
            numbers = [int(n.strip()) - 1 for n in group_str.split(',')]
            groups.append(numbers)
        return groups
    except Exception as e:
        print("âš ï¸ ê·¸ë£¹ íŒŒì‹± ì‹¤íŒ¨:", e)
        return []

def get_gpt_duplicate_groups(headlines: List[str], step_desc: str = "") -> List[List[int]]:
    system_prompt = "ë„ˆëŠ” ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ì¤‘ ì¤‘ë³µëœ ë‚´ìš©ì„ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ì–´ì£¼ëŠ” AIì•¼."
    user_prompt = "ë‹¤ìŒì€ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ë¦¬ìŠ¤íŠ¸ì•¼. ê°™ì€ ì‚¬ê±´ì´ë‚˜ ë‚´ìš©ì€ í•˜ë‚˜ì˜ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ê³ , ê·¸ë£¹ë§ˆë‹¤ ê¸°ì‚¬ ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸ë¡œ ì•Œë ¤ì¤˜.\n\n"

    for i, h in enumerate(headlines):
        user_prompt += f"{i+1}. {h}\n"
    user_prompt += "\nì¶œë ¥ì€ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ í•´ì¤˜: [[1, 2], [3], [4, 5]]"

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.2
        )
        content = response.choices[0].message.content
        groups = parse_gpt_group_output(content)
        print(f"âœ… {step_desc} ê·¸ë£¹ ìˆ˜: {len(groups)} / ê¸°ì‚¬ {len(headlines)}ê±´")
        return groups
    except Exception as e:
        print(f"âŒ GPT í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return [[i] for i in range(len(headlines))]  # fallback: ì „ë¶€ ë…ë¦½ ê¸°ì‚¬

def choose_by_media_priority(group_df: pd.DataFrame) -> pd.Series:
    for media in MEDIA_PRIORITY:
        match = group_df[group_df["ë§¤ì²´ëª…"] == media]
        if not match.empty:
            return match.iloc[0]
    return group_df.iloc[0]

def deduplicate_news_with_gpt(df: pd.DataFrame, batch_size: int = 20) -> pd.DataFrame:
    print("ğŸš€ GPT ì¤‘ë³µ ì œê±° ì‹œì‘")
    df = df.copy().reset_index(drop=True)

    headline_batches = [df.iloc[i:i+batch_size] for i in range(0, len(df), batch_size)]
    selected_rows = []

    for i, batch_df in enumerate(headline_batches):
        print(f"\nğŸ“¦ ë°°ì¹˜ {i+1}/{len(headline_batches)}")
        headlines = batch_df['í—¤ë“œë¼ì¸'].tolist()
        groups = get_gpt_duplicate_groups(headlines, step_desc=f"ë°°ì¹˜ {i+1}")

        for group in groups:
            group_df = batch_df.iloc[group]
            selected = choose_by_media_priority(group_df)
            selected_rows.append(selected)

    result_df = pd.DataFrame(selected_rows).reset_index(drop=True)
    print(f"\nğŸ‰ ìµœì¢… ëŒ€í‘œ ê¸°ì‚¬ ìˆ˜: {len(result_df)} / ì›ë³¸ {len(df)}")
    return result_df


def deduplicate_news_with_gpt_twopass(df: pd.DataFrame, batch_size_first: int = 20, batch_size_second: int = 50) -> pd.DataFrame:
    """
    GPT ê¸°ë°˜ ë‰´ìŠ¤ ì¤‘ë³µ ì œê±° (2ë‹¨ê³„ ë°©ì‹)
    1ì°¨: ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì¤‘ë³µ ì œê±°
    2ì°¨: 1ì°¨ ëŒ€í‘œ ê¸°ì‚¬ë“¤ ê°„ cross-batch ì¤‘ë³µ ì œê±°
    """
    print("\nğŸš€ [1ì°¨] ë°°ì¹˜ë³„ ì¤‘ë³µ ì œê±° ì‹œì‘")
    first_pass_df = deduplicate_news_with_gpt(df, batch_size=batch_size_first)

    print("\nğŸ” [2ì°¨] ëŒ€í‘œ ê¸°ì‚¬ë“¤ ê°„ cross-batch ì¤‘ë³µ ì œê±° ì‹œì‘")
    second_pass_df = deduplicate_news_with_gpt(first_pass_df, batch_size=batch_size_second)

    print(f"\nğŸ‰ ìµœì¢… ëŒ€í‘œ ê¸°ì‚¬ ìˆ˜: {len(second_pass_df)} / ì›ë³¸ {len(df)}")
    return second_pass_df


df_total = deduplicate_news_with_gpt_twopass(df_total)



# âœ… 9. 3ì¤„ ìš”ì•½ í•¨ìˆ˜
def summarize_all_in_3_lines(df):
    df["ì£¼ìš”ë‚´ìš©"] = ""

    print(f"\nğŸ“Œ [1ë‹¨ê³„] ì „ì²´ ê¸°ì‚¬ 3ì¤„ ìš”ì•½ ì‹œì‘ (ì´ {len(df)}ê±´)")

    for idx, row in df.iterrows():
        content = row["ë³¸ë¬¸"]
        if not isinstance(content, str) or not content.strip():
            print(f"âš ï¸ ë³¸ë¬¸ ì—†ìŒ (idx={idx}) â†’ ê±´ë„ˆëœ€")
            continue

        prompt =  f"""ë„ˆëŠ” ë‰´ìŠ¤ ìš”ì•½ ì „ë¬¸ Assistantì•¼.

                    ë‹¤ìŒ ë‰´ìŠ¤ ë³¸ë¬¸ì„ 3ì¤„ ì´ë‚´ë¡œ ìš”ì•½í•´ì¤˜.

                    - í—¤ë“œë¼ì¸ì²˜ëŸ¼ ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ ë‚´ìš© ìœ„ì£¼ë¡œ ì •ë¦¬í•´.
                    - ì£¼ì–´ëŠ” ìƒëµí•˜ê±°ë‚˜ ìµœì†Œí™”í•˜ê³ , ì¤‘ìš”í•œ ì •ë³´ë¶€í„° ì „ë‹¬í•´.
                    - ê° ë¬¸ì¥ì€ ë°˜ë“œì‹œ '~ë‹¤'ë¡œ ëë‚˜ëŠ” ì„œìˆ í˜•ì´ì–´ì•¼ í•´.
                    - '~ìš”'ë‚˜ '~í•©ë‹ˆë‹¤' ê°™ì€ ì–´íˆ¬ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆ.
                    - ë„ˆì˜ ìƒê°ë³´ë‹¤ëŠ” ì‚¬ì‹¤ì„ ì•Œë ¤ì£¼ëŠ”ë° ì¤‘ì ì„ ë‘ê³  ì‘ì„±í•´ì¤˜.
                    - ì„¤ëª…ì¡°ë³´ë‹¤ëŠ” ë³´ë„ ë¬¸ì¥ ìŠ¤íƒ€ì¼ë¡œ ì¨ì¤˜.
                    - ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ì–´ë‚˜ ë°°ê²½ ì„¤ëª…ì€ ìƒëµí•´ë„ ì¢‹ì•„.

                    {content}"""

        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‰´ìŠ¤ 3ì¤„ ìš”ì•½ê¸°"},
                    {"role": "user", "content": prompt}
                ]
            )
            summary = response.choices[0].message.content.strip()
            df.at[idx, "ì£¼ìš”ë‚´ìš©"] = summary
            print(f"âœ… ìš”ì•½ ì™„ë£Œ (idx={idx}, í—¤ë“œë¼ì¸: {row['í—¤ë“œë¼ì¸'][:10]})")

        except Exception as e:
            print(f"âš ï¸ ìš”ì•½ ì‹¤íŒ¨ (idx={idx}): {e}")
            continue

    print("\nğŸ“Œ ì „ì²´ ê¸°ì‚¬ 3ì¤„ ìš”ì•½ ì™„ë£Œ")
    return df

# df_total = summarize_all_in_3_lines(df_total)

# âœ… 10. ì¤‘ìš” ê¸°ì‚¬ ì„ ë³„ í•¨ìˆ˜

def analyze_articles_batch(df, batch_size=5, max_retries=5):
    df["ëŒ€ê¸°ì—… ê´€ë ¨"] = ""
    df["HR ê´€ë ¨"] = ""
    df["ì •ì±…/ë²•ì•ˆ ê´€ë ¨"] = ""
    df["ì¤‘ìš”ì—¬ë¶€"] = ""
    df["ê²½ì œ/ì‚°ì—… ê´€ë ¨"] = ""
    df["ë³´í—˜/ê¸ˆìœµ ê´€ë ¨"] = ""
    df["ì¤‘ìš”ë„"] = 0

    print(f"\nğŸ“Œ [2ë‹¨ê³„] ê¸°ì‚¬ ë¶„ì„ ì‹œì‘ (ì´ {len(df)}ê±´, {batch_size}ê°œì”© ë¬¶ìŒ)")
    total_success = 0
    total_failed = 0
    retry_indices = set()

    def run_batch(batch_df, index_map):
        prompt_lines = []
        for i, idx in enumerate(batch_df.index, 1):
            prompt_lines.append(f"{i}. {batch_df.at[idx, 'í—¤ë“œë¼ì¸']}")
            index_map[i] = idx

        prompt = "\n".join(prompt_lines)

        system_msg = (
            "ë‹¹ì‹ ì€ ëŒ€ê¸°ì—… ì¸ì‚¬íŒ€ì˜ ì¸ì‚¬ ë‹´ë‹¹ìì…ë‹ˆë‹¤.\n"
            "ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ ì œëª©ë“¤ì„ ê²€í† í•˜ê³  ê° ì œëª©ì— ëŒ€í•´ ë‹¤ìŒ ë‹¤ì„¯ ê°€ì§€ í•­ëª©ì— ëŒ€í•´ ê°ê° 'O' ë˜ëŠ” 'X'ë¡œ íŒë‹¨í•˜ì„¸ìš”.\n\n"
            "1. ì´ ê¸°ì‚¬ê°€ ì‚¼ì„±ê·¸ë£¹ í˜¹ì€ ëŒ€ê¸°ì—…ê³¼ ê´€ë ¨ì´ ìˆëŠ”ê°€?\n"
            "2. ì´ ê¸°ì‚¬ê°€ HR ë¶€ì„œ(ì±„ìš©, ì¸ì‚¬, ì œë„, ì„ê¸ˆ, êµìœ¡, ë…¸ë¬´ ë“±)ì—ì„œ ê´€ì‹¬ì„ ê°€ì§ˆë§Œí•œ ë‚´ìš©ì¸ê°€?\n"
            "3. ì •ì±…/ë²•ì•ˆ ë“±ì˜ ì œë„ ë³€í™”ì™€ ê´€ë ¨ëœ ë‚´ìš©ì¸ê°€?\n"
            "4. ê²½ì œ/ì‚°ì—…ê³„ì™€ ê´€ë ¨ ë‚´ìš©ì¸ê°€?\n"
            "5. ë³´í—˜/ê¸ˆìœµì—…ê³„ ê´€ë ¨ ë‚´ìš©ì¸ê°€?\n\n"
            "ê° ê¸°ì‚¬ì— ëŒ€í•´ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\n"
            "1. ëŒ€ê¸°ì—… ê´€ë ¨: O, HR ê´€ì‹¬: O, ì •ì±…/ë²•ì•ˆ/íŒë¡€ ê´€ë ¨: X, ê²½ì œ/ì‚°ì—… ê´€ë ¨: O, ë³´í—˜/ê¸ˆìœµ ê´€ë ¨: X\n"
            "...\n\n"
            f"ê¸°ì‚¬ ëª©ë¡:\n{prompt}"
        )

        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "system", "content": system_msg}]
            )
            reply = response.choices[0].message.content.strip()
            lines = reply.split("\n")

            success = 0
            failed_ids = []

            for line in lines:
                if not line.strip():
                    continue

                parts = line.split('. ', 1)
                if len(parts) < 2:
                    continue

                try:
                    gpt_num = int(parts[0])
                except:
                    continue

                content = parts[1]
                fields = [f.strip() for f in content.split(',')]
                if len(fields) < 5:
                    failed_ids.append(index_map[gpt_num])
                    continue

                values = []
                for f in fields:
                    if ':' in f:
                        values.append(f.split(':')[1].strip())
                    else:
                        values.append('X')

                original_idx = index_map.get(gpt_num)
                if original_idx is not None and len(values) == 5:
                    df.at[original_idx, "ëŒ€ê¸°ì—… ê´€ë ¨"] = values[0]
                    df.at[original_idx, "HR ê´€ë ¨"] = values[1]
                    df.at[original_idx, "ì •ì±…/ë²•ì•ˆ ê´€ë ¨"] = values[2]
                    df.at[original_idx, "ê²½ì œ/ì‚°ì—… ê´€ë ¨"] = values[3]
                    df.at[original_idx, "ë³´í—˜/ê¸ˆìœµ ê´€ë ¨"] = values[4]

                    relevance_score = values.count("O")
                    df.at[original_idx, "ì¤‘ìš”ë„"] = relevance_score
                    if relevance_score >= 3:
                        df.at[original_idx, "ì¤‘ìš”ì—¬ë¶€"] = "V"

                    success += 1
                else:
                    failed_ids.append(original_idx)

            return success, failed_ids

        except Exception as e:
            print(f"âš ï¸ GPT ë¶„ì„ ì‹¤íŒ¨ (ì˜ˆì™¸): {e}")
            return 0, list(index_map.values())

    # 1ì°¨ ë¶„ì„
    total_batches = math.ceil(len(df) / batch_size)
    for batch_num in range(total_batches):
        start_idx = batch_num * batch_size
        end_idx = min(start_idx + batch_size, len(df))
        batch_df = df.iloc[start_idx:end_idx]
        index_map = {}

        print(f"\nğŸ“¦ Batch {batch_num+1}: í¬ë¡¤ë§ ì¤‘...")
        success, failed = run_batch(batch_df, index_map)
        total_success += success
        total_failed += len(batch_df) - success
        retry_indices.update(failed)

        print(f"âœ… ì„±ê³µ: {success} / âŒ ì‹¤íŒ¨: {len(failed)}")

    # ì¬ì‹œë„
    retry_count = 0
    while retry_indices and retry_count < max_retries:
        retry_count += 1
        print(f"\nğŸ” ì¬ì‹œë„ {retry_count}ì°¨ ì‹œì‘ (ë‚¨ì€ ì‹¤íŒ¨ ê¸°ì‚¬ ìˆ˜: {len(retry_indices)})")

        retry_list = list(retry_indices)
        retry_indices = set()

        for i in range(0, len(retry_list), batch_size):
            batch_ids = retry_list[i:i+batch_size]
            batch_df = df.loc[batch_ids]
            index_map = {}

            success, failed = run_batch(batch_df, index_map)
            total_success += success
            total_failed -= success
            retry_indices.update(failed)

            print(f"â†©ï¸ ì¬ì‹œë„ ì„±ê³µ: {success} / ì‹¤íŒ¨: {len(failed)}")

    print(f"\nâœ… ë¶„ì„ ì™„ë£Œ: ì´ {total_success}ê±´ ì„±ê³µ / {len(df)}ê±´ ì¤‘")
    if total_failed > 0:
        print(f"â— ìµœì¢… ì‹¤íŒ¨ ê¸°ì‚¬: {total_failed}ê±´ (ì¬ì‹œë„ {max_retries}íšŒ í›„ ì‹¤íŒ¨)")

    return df


# âœ… 12. ì „ì²´ ì‹¤í–‰ ìˆœì„œ
print("\nğŸ§  ChatGPTë¥¼ ì´ìš©í•œ ì¤‘ìš” ê¸°ì‚¬ ì²´í¬ ì¤‘...")
df_total = analyze_articles_batch(df_total)

# âœ… 12-1) í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ (ìˆœì„œ ë³´ì¥)
df_total = df_total[[
    "í‚¤ì›Œë“œ", "ì¼ì", "í—¤ë“œë¼ì¸", "ë§¤ì²´ëª…", "ë³¸ë¬¸", "ì£¼ìš”ë‚´ìš©",
    "ëŒ€ê¸°ì—… ê´€ë ¨", "HR ê´€ë ¨", "ì •ì±…/ë²•ì•ˆ ê´€ë ¨", "ê²½ì œ/ì‚°ì—… ê´€ë ¨",
    "ë³´í—˜/ê¸ˆìœµ ê´€ë ¨", "ì¤‘ìš”ë„", "ì¤‘ìš”ì—¬ë¶€"
]].copy()
# 12-2) 'êµ¬ë¶„'ì— ëŒ€í•œ ì¹´í…Œê³ ë¦¬ ìˆœì„œ ì§€ì •
# category_order = ["ì±„ìš©", "ë…¸ì‚¬", "ì„ê¸ˆ", "ì œë„", "ë³µì§€", "ê´€ê³„ì‚¬", "í˜„ëŒ€í•´ìƒ", "DBì†ë³´", "KBì†ë³´", "ë©”ë¦¬ì¸ "]
# df_total["í‚¤ì›Œë“œ"] = pd.Categorical(df_total["í‚¤ì›Œë“œ"], categories=category_order, ordered=True)

#12-3) ì •ë ¬: êµ¬ë¶„(ìœ„ ìˆœì„œëŒ€ë¡œ), ì¼ì(ë‚´ë¦¼ì°¨ìˆœ), í—¤ë“œë¼ì¸(ë‚´ë¦¼ì°¨ìˆœ)
df_total = df_total.sort_values(
    by=["ì¤‘ìš”ë„", "í‚¤ì›Œë“œ", "ì¼ì", "í—¤ë“œë¼ì¸"],
    ascending=[False, True, False, False]
)

print("\nğŸ‰ ì „ì²´ ì‘ì—… ì™„ë£Œ!")


# âœ… 13. Google ì‹œíŠ¸ ì—…ë¡œë“œ (ë®ì–´ì“°ê¸°)
sheet_id = "1l89Eca3CsjLEjG-9_raVMy6Y_sYE4BLA-XRtgwEhHEc"
sheet_name = "ë„¤ì´ë²„API(ì²¨ë¶€íŒŒì¼ìš©)"


# ì‹œíŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
sheet = gc.open_by_key(sheet_id)
worksheet = sheet.worksheet(sheet_name)

# âœ… A3 ì´í›„ë§Œ ì§€ìš°ê¸°
worksheet.batch_clear(["A3:Z"])

# âœ… A3 ì…€ë¶€í„° DataFrame ì €ì¥
set_with_dataframe(worksheet, df_total, row=3, col=1)
worksheet.update("A2", [[f"ì—…ë°ì´íŠ¸ ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"]])


print("âœ… Google ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì €ì¥ ì™„ë£Œ!")
print("ğŸ”— ë§í¬:", sheet.url)
